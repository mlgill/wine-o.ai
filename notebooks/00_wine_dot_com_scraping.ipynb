{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Wine.com\n",
    "\n",
    "Scrape information, reviews, and wine labels from [Wine.com](http://wine.com). This scrape was parallelized over 16 cores using SOCKS5 proxies to mask the incoming IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-08-11T11:38:57.273918",
     "start_time": "2016-08-11T11:38:57.267139"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "import multiprocess as mp\n",
    "\n",
    "import dill\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the list of wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-08-11T12:06:20.048136",
     "start_time": "2016-08-11T12:06:20.041419"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_list = [range(0,52), range(0,22), range(0,2), range(0,5), range(0,3), range(0,2)]\n",
    "url_list = ['http://www.wine.com/v6/Red-Wine/wine/list.aspx?N=7155+124&pagelength=100&Nao={}',\n",
    "            'http://www.wine.com/v6/White-Wine/wine/list.aspx?N=7155+125&pagelength=100&Nao={}',\n",
    "            'http://www.wine.com/v6/Rose-Wine/wine/list.aspx?N=7155+126&pagelength=100&Nao={}',\n",
    "            'http://www.wine.com/v6/Champagne-and-Sparkling/wine/list.aspx?N=7155+123&pagelength=100&Nao={}',\n",
    "            'http://www.wine.com/v6/Dessert-Sherry-and-Port/wine/list.aspx?N=7155+128&pagelength=100&Nao={}',\n",
    "            'http://www.wine.com/v6/Sake/wine/list.aspx?N=7155+134&pagelength=100&Nao={}']\n",
    "color_list = ['red', 'white', 'rose', 'sparkling', 'dessert', 'sake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-08-11T12:07:01.277160",
     "start_time": "2016-08-11T12:06:43.806369"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.wine.com/v6/Red-Wine/wine/list.aspx?N=7155+124&pagelength=100&Nao={}\n",
      "http://www.wine.com/v6/White-Wine/wine/list.aspx?N=7155+125&pagelength=100&Nao={}\n",
      "http://www.wine.com/v6/Rose-Wine/wine/list.aspx?N=7155+126&pagelength=100&Nao={}\n",
      "http://www.wine.com/v6/Champagne-and-Sparkling/wine/list.aspx?N=7155+123&pagelength=100&Nao={}\n",
      "http://www.wine.com/v6/Dessert-Sherry-and-Port/wine/list.aspx?N=7155+128&pagelength=100&Nao={}\n",
      "http://www.wine.com/v6/Sake/wine/list.aspx?N=7155+134&pagelength=100&Nao={}\n"
     ]
    }
   ],
   "source": [
    "wine_urls = list()\n",
    "\n",
    "for page_range, url_base, color in zip(page_list, url_list, color_list):\n",
    "    print url_base\n",
    "    for pg in page_range:\n",
    "        url_no = 1+100*pg\n",
    "\n",
    "        # Get the HTML\n",
    "        req = requests.get(url_base.format(url_no))\n",
    "        soup = BeautifulSoup(req.text, 'lxml')\n",
    "\n",
    "        # Get the item list \n",
    "        item_list = soup.find(attrs={'class':'productList'}).find_all(attrs={'class':'verticalListItem'})\n",
    "        item_list = [x.find('a',href=True).get('href') for x in item_list]\n",
    "        item_list = [(color, 'http://www.wine.com'+x) for x in item_list]\n",
    "        wine_urls.extend(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine_urls = [(x,y,z) for (x,y),z in zip(wine_urls, range(len(wine_urls)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-08-11T12:07:13.108070",
     "start_time": "2016-08-11T12:07:13.101576"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../priv/pkl/00_wine_dot_com_url_list.pkl','w') as fh:\n",
    "    dill.dump(wine_urls, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8520"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wine_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the SSH tunnels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to create the Selenium web driver\n",
    "\n",
    "def make_driver(port):\n",
    "    \n",
    "    service_args = ['--proxy=127.0.0.1:{}'.format(port), '--proxy-type=socks5']\n",
    "    \n",
    "    dcap = dict(DesiredCapabilities.PHANTOMJS)\n",
    "    ua = UserAgent()\n",
    "    dcap.update({'phantomjs.page.settings.userAgent':ua.random})\n",
    "    \n",
    "    phantom_path = '/usr/bin/phantomjs'\n",
    "    \n",
    "    driver = webdriver.PhantomJS(phantom_path, \n",
    "                                   desired_capabilities=dcap,\n",
    "                                   service_args=service_args)\n",
    "    \n",
    "    # load an url to clear the initial question about location\n",
    "    initial_url = 'http://www.wine.com/v6/Schug-Sonoma-Coast-Pinot-Noir-2014/wine/148901/Detail.aspx'\n",
    "    driver.get(initial_url)\n",
    "    time.sleep(1.5)\n",
    "\n",
    "    try:\n",
    "        elem = driver.find_element_by_xpath('//*[@id=\"StateSelectShopButton\"]')\n",
    "        elem.click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn all the user reviews into their own table\n",
    "\n",
    "def get_review_table(review_list, full_url, url_no):\n",
    "    \n",
    "    author_list = list()\n",
    "    location_list = list()\n",
    "    rating_list = list()\n",
    "    date_list = list()\n",
    "    style_list = list()\n",
    "    review_text_list = list()\n",
    "\n",
    "    for review in review_list:\n",
    "\n",
    "        # author\n",
    "        try:\n",
    "            author = review.find(attrs={'class':'reviewAuthorAlias'}).text.strip()\n",
    "        except:\n",
    "            author = ''\n",
    "        author_list.append(author)\n",
    "\n",
    "        # location\n",
    "        try:\n",
    "            location = review.find(attrs={'class':'reviewAuthorLocation'}).text.strip()\n",
    "        except:\n",
    "            location = ''\n",
    "        location_list.append(location)\n",
    "\n",
    "        # rating\n",
    "        try:\n",
    "            rating = review.find(attrs={'class':'starRatingText'}).text\n",
    "        except:\n",
    "            rating = ''\n",
    "        rating_list.append(rating)\n",
    "\n",
    "        # date\n",
    "        try:\n",
    "            date = review.find(attrs={'class':'reviewDate'}).text.strip()\n",
    "        except:\n",
    "            date = ''\n",
    "        date_list.append(date)\n",
    "\n",
    "        # style\n",
    "        try:\n",
    "            style = review.find(attrs={'class':'reviewAttributes'}).text.replace('Style','').strip()\n",
    "        except:\n",
    "            style = ''\n",
    "        style_list.append(style)\n",
    "\n",
    "        # review\n",
    "        try:\n",
    "            review_text = review.find(attrs={'class':'reviewText'}).text.strip()\n",
    "        except:\n",
    "            review_text = ''\n",
    "        review_text_list.append(review_text)\n",
    "\n",
    "\n",
    "    review_df = pd.DataFrame({'author':author_list, 'location':location_list,\n",
    "                              'rating':rating_list, 'date':date_list,\n",
    "                              'style':style_list, 'review':review_text_list,\n",
    "                              'url':[full_url]*len(review_list),\n",
    "                              'url_no':[url_no]*len(review_list)},\n",
    "                              index=pd.Index(range(len(review_list))))\n",
    "    return review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The scraping function that returns both the wine data and the review\n",
    "def scrape_data(driver, url):\n",
    "    \n",
    "    full_url = url[1]\n",
    "    color = url[0]\n",
    "    url_no = url[2]\n",
    "    \n",
    "    # open the full url\n",
    "    driver.get(full_url)\n",
    "    time.sleep(2.5)\n",
    "\n",
    "    # try to select the image to get the larger version\n",
    "    # and get the main text\n",
    "    try:\n",
    "        hover = driver.find_element_by_xpath('/html/body/main/section[1]/div[2]/div')\n",
    "        hover = ActionChains(driver).move_to_element(hover)\n",
    "        hover.perform()\n",
    "        time.sleep(0.5)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    html = driver.page_source\n",
    "    main_soup = BeautifulSoup(html, 'lxml')\n",
    "    wine_text = main_soup.find(attrs={'class': 'productAbstract'})\n",
    "\n",
    "    # get the html for the reviews\n",
    "    try:\n",
    "        elem = driver.find_element_by_xpath('/html/body/main/section[3]/ul[1]/li[3]/a')\n",
    "        elem.click()\n",
    "        time.sleep(0.5)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    html = driver.page_source\n",
    "    review_soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    try:\n",
    "        review_list = review_soup.find(attrs={'class':'topReviews'}).find_all(attrs={'class':'review'})\n",
    "    except:\n",
    "        review_list = []\n",
    "\n",
    "    #### WINE DATA ####\n",
    "    # image url\n",
    "    try:\n",
    "        image_url = main_soup.find(attrs={'class':'flyOutZoomViewport'}).find('img').get('src')\n",
    "    except:\n",
    "        try:\n",
    "            image_url = main_soup.find(attrs={'class':'hero'}).get('src')\n",
    "        except:\n",
    "            image_url = ''\n",
    "\n",
    "    # wine\n",
    "    try:\n",
    "        wine = wine_text.find('h1').text.strip()\n",
    "    except:\n",
    "        wine = ''\n",
    "\n",
    "    try:\n",
    "        year = re.search(r\"\"\"((?:20|19)[0-9]{2})\"\"\", wine).group(1)\n",
    "        wine = wine.replace(year, '').strip()\n",
    "    except:\n",
    "        year = ''\n",
    "\n",
    "    # kind, region\n",
    "    try:\n",
    "        kind_loc_match = re.search(r\"\"\"(.+) from (.+)\"\"\", wine_text.find('h2').text.strip())\n",
    "    except:\n",
    "        kind = ''\n",
    "        region = ''\n",
    "    else:\n",
    "        try:\n",
    "            kind = kind_loc_match.group(1)\n",
    "        except:\n",
    "            kind = ''\n",
    "\n",
    "        try:\n",
    "            region = kind_loc_match.group(2)\n",
    "        except:\n",
    "            region = ''\n",
    "\n",
    "    # review\n",
    "    try:\n",
    "        review = main_soup.find(attrs={'class':'tabContent aboutTheWine active'}).find(attrs={'itemprop':'description'}).text\n",
    "    except:\n",
    "        review = ''\n",
    "\n",
    "    # winery\n",
    "    try:\n",
    "        winery = main_soup.find(attrs={'class':'tabContent theWinery'}).find('h3').text.strip()\n",
    "    except:\n",
    "        winery = ''\n",
    "\n",
    "    # ratings\n",
    "    try:\n",
    "        ratings_list = [x.text.strip() \n",
    "                        for x in \n",
    "                        wine_text.find_all(attrs={'class': 'wineRatings'})]\n",
    "\n",
    "        ratings_list = [re.findall(r\"\"\"((?:20|19)[0-9]{2}|[A-Z]{2}[0-9]{2})\"\"\", x) \n",
    "                        for x in ratings_list]\n",
    "\n",
    "        recent = [float(re.search(r\"\"\"[0-9]+\"\"\", x).group(0)) for x in ratings_list[0]]\n",
    "        if len(recent) >= 1:\n",
    "            rating = np.array(recent).mean()\n",
    "        else:\n",
    "            rating = np.NaN\n",
    "    except:\n",
    "        rating = np.NaN\n",
    "\n",
    "\n",
    "    df = pd.DataFrame({'wine':wine, 'year':year, 'kind':kind,\n",
    "                       'region':region, 'review':review,\n",
    "                       'winery':winery, 'rating':rating,\n",
    "                       'color':color, 'url':full_url,\n",
    "                       'image':image_url, 'url_no':url_no}, index=pd.Index([0]))\n",
    "    \n",
    "    # download the image\n",
    "    if len(image_url) > 0:\n",
    "        if image_url.startswith('//'):\n",
    "            image_url = 'http:' + image_url\n",
    "            \n",
    "        filext = os.path.splitext(image_url)[-1]\n",
    "        path = '../priv/images/wine_dot_com_' + str(url_no) + filext\n",
    "        req = requests.get(image_url)\n",
    "        \n",
    "        if req.status_code == 200:\n",
    "            with open(path, 'wb') as f:\n",
    "                for chunk in req:\n",
    "                    f.write(chunk)\n",
    "            \n",
    "    \n",
    "    # get the review\n",
    "    review_df = None\n",
    "    if len(review_list) >= 1:\n",
    "        try:\n",
    "            review_df = get_review_table(review_list, full_url, url_no)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return df, review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def master_scrape(args):\n",
    "    \n",
    "    port = args[0]\n",
    "    url_list = args[1]\n",
    "    \n",
    "    driver = make_driver(port)\n",
    "    \n",
    "    data_list = list()\n",
    "    review_list = list()\n",
    "    \n",
    "    for url in url_list:\n",
    "        if url[-1] % 100 == 0:\n",
    "            print url[-1]\n",
    "            \n",
    "            # write the data\n",
    "            if len(data_list) > 0:\n",
    "                data_df = pd.concat([x for x in data_list]).reset_index(drop=True)\n",
    "                data_df.to_pickle('../priv/pkl/00_wine_dot_com_data_{}.pkl'.format(url[-1]-100))\n",
    "            \n",
    "            if len(review_list) > 0:\n",
    "                review_df = pd.concat([x for x in review_list]).reset_index(drop=True)\n",
    "                review_df.to_pickle('../priv/pkl/00_wine_dot_com_review_{}.pkl'.format(url[-1]-100))\n",
    "            \n",
    "            data_list = list()\n",
    "            review_list = list()\n",
    "            \n",
    "        ret_data = scrape_data(driver, url)\n",
    "        data_list.append(ret_data[0])\n",
    "        \n",
    "        if ret_data[1] is not None:\n",
    "            review_list.append(ret_data[1])\n",
    "            \n",
    "    # save the final data dataset\n",
    "    data_df = pd.concat([x for x in data_list]).reset_index(drop=True)\n",
    "    data_df.to_pickle('../priv/pkl/00_wine_dot_com_data_{}.pkl'.format((url[-1]//100)*100))\n",
    "            \n",
    "    review_df = pd.concat([x for x in review_list]).reset_index(drop=True)\n",
    "    review_df.to_pickle('../priv/pkl/00_wine_dot_com_review_{}.pkl'.format((url[-1]//100)*100))\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start the ssh tunnels\n",
    "! ../priv/scripts/ssh_tunnels.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncomputers = 16\n",
    "nthreads = 16\n",
    "\n",
    "port_nos = np.array([8081+x for x in range(ncomputers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the url list up for scraping\n",
    "split_urls = list()\n",
    "\n",
    "for i in range(nthreads):\n",
    "    begin = i*500\n",
    "    if i != (nthreads):\n",
    "        end = (i+1)*500\n",
    "        split_urls.append(wine_urls[begin:end])\n",
    "    else:\n",
    "        split_urls.append(wine_urls[begin:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "3500\n",
      "2500\n",
      "1500\n",
      "5500\n",
      "5000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "7500\n",
      "7000\n",
      "0\n",
      "6000\n",
      "4500\n",
      "6500\n",
      "500\n",
      "2600\n",
      "7600\n",
      "1600\n",
      "5600\n",
      "3100\n",
      "1100\n",
      "4100\n",
      "3600\n",
      "6600\n",
      "100\n",
      "5100\n",
      "7100\n",
      "600\n",
      "6100\n",
      "2100\n",
      "4600\n",
      "2700\n",
      "1700\n",
      "3200\n",
      "7700\n",
      "5700\n",
      "1200\n",
      "6700\n",
      "5200\n",
      "3700\n",
      "4200\n",
      "200\n",
      "4700\n",
      "700\n",
      "7200\n",
      "6200\n",
      "2200\n",
      "2800\n",
      "1800\n",
      "3300\n",
      "7800\n",
      "5800\n",
      "1300\n",
      "6800\n",
      "3800\n",
      "5300\n",
      "4800\n",
      "4300\n",
      "800\n",
      "300\n",
      "6300\n",
      "7300\n",
      "2300\n",
      "2900\n",
      "1900\n",
      "3400\n",
      "7900\n",
      "5900\n",
      "3900\n",
      "1400\n",
      "5400\n",
      "6900\n",
      "4900\n",
      "900\n",
      "4400\n",
      "6400\n",
      "7400\n",
      "400\n",
      "2400\n"
     ]
    }
   ],
   "source": [
    "# Run the scrape\n",
    "pool = mp.Pool(processes=nthreads)\n",
    "results = pool.map(master_scrape, [x for x in zip(port_nos, split_urls)])\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n"
     ]
    }
   ],
   "source": [
    "# The last ~500 urls were never scraped, so do these\n",
    "master_scrape([port_nos[0], wine_urls[8000:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_list = glob('../priv/pkl/00_wine_dot_com_data_*.pkl')\n",
    "review_list = glob('../priv/pkl/00_wine_dot_com_review_*.pkl')\n",
    "\n",
    "int_sorter = lambda x: int(re.search(r\"\"\"_([0-9]+)\\.\"\"\", x).group(1))\n",
    "data_list = sorted(data_list, key=int_sorter)\n",
    "review_list = sorted(review_list, key=int_sorter)\n",
    "\n",
    "images_list = glob('../priv/images/wine_dot_com_*.*')\n",
    "images_list = map(int_sorter, images_list)\n",
    "images_list = sorted(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_data(file_list):\n",
    "    \n",
    "    # Load and combine the data for the list of files\n",
    "    combined_data = list()\n",
    "    \n",
    "    for fil in file_list:\n",
    "        df = pd.read_pickle(fil)\n",
    "        combined_data.append(df)\n",
    "\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find missing data\n",
    "def find_missing(url_nos, wine_urls=wine_urls):\n",
    "    range_array = np.array(range(len(wine_urls)))\n",
    "    missing_urls = np.invert(np.in1d(range_array, url_nos))\n",
    "    return range_array[missing_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>image</th>\n",
       "      <th>kind</th>\n",
       "      <th>rating</th>\n",
       "      <th>region</th>\n",
       "      <th>review</th>\n",
       "      <th>url</th>\n",
       "      <th>url_no</th>\n",
       "      <th>wine</th>\n",
       "      <th>winery</th>\n",
       "      <th>...</th>\n",
       "      <th>image</th>\n",
       "      <th>kind</th>\n",
       "      <th>rating</th>\n",
       "      <th>region</th>\n",
       "      <th>review</th>\n",
       "      <th>url</th>\n",
       "      <th>url_no</th>\n",
       "      <th>wine</th>\n",
       "      <th>winery</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>http://cdn.fluidretail.net/customers/c1477/14/...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>91.5</td>\n",
       "      <td>Sonoma Coast, Sonoma County, California</td>\n",
       "      <td>This 100% Pinot Noir cuvee is from grapes grow...</td>\n",
       "      <td>http://www.wine.com/v6/Schug-Sonoma-Coast-Pino...</td>\n",
       "      <td>0</td>\n",
       "      <td>Schug Sonoma Coast Pinot Noir</td>\n",
       "      <td>Schug Estate Winery</td>\n",
       "      <td>...</td>\n",
       "      <td>http://cdn.fluidretail.net/customers/c1477/87/...</td>\n",
       "      <td>Non-Vintage Sparkling Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Cordon Negro Brut is crisp, clean and well bal...</td>\n",
       "      <td>http://www.wine.com/v6/Freixenet-Sparkling-Cor...</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>Freixenet Sparkling Cordon Negro Brut (187ML S...</td>\n",
       "      <td>Freixenet Winery</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 946 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  color                                              image        kind rating  \\\n",
       "0   red  http://cdn.fluidretail.net/customers/c1477/14/...  Pinot Noir   91.5   \n",
       "\n",
       "                                    region  \\\n",
       "0  Sonoma Coast, Sonoma County, California   \n",
       "\n",
       "                                              review  \\\n",
       "0  This 100% Pinot Noir cuvee is from grapes grow...   \n",
       "\n",
       "                                                 url url_no  \\\n",
       "0  http://www.wine.com/v6/Schug-Sonoma-Coast-Pino...      0   \n",
       "\n",
       "                            wine               winery ...   \\\n",
       "0  Schug Sonoma Coast Pinot Noir  Schug Estate Winery ...    \n",
       "\n",
       "                                               image  \\\n",
       "0  http://cdn.fluidretail.net/customers/c1477/87/...   \n",
       "\n",
       "                         kind rating region  \\\n",
       "0  Non-Vintage Sparkling Wine    NaN  Spain   \n",
       "\n",
       "                                              review  \\\n",
       "0  Cordon Negro Brut is crisp, clean and well bal...   \n",
       "\n",
       "                                                 url  url_no  \\\n",
       "0  http://www.wine.com/v6/Freixenet-Sparkling-Cor...  8500.0   \n",
       "\n",
       "                                                wine            winery year  \n",
       "0  Freixenet Sparkling Cordon Negro Brut (187ML S...  Freixenet Winery       \n",
       "\n",
       "[1 rows x 946 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the data and write to a file\n",
    "data_df = aggregate_data(data_list)\n",
    "data_df = pd.concat(data_df, axis=1)\n",
    "data_df.to_pickle('../priv/pkl/00_wine_dot_com_data_combined.pkl')\n",
    "\n",
    "data_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>style</th>\n",
       "      <th>url</th>\n",
       "      <th>url_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colbyalbo</td>\n",
       "      <td>5/20/2016</td>\n",
       "      <td>Lafayette, LA</td>\n",
       "      <td>5</td>\n",
       "      <td>An aromatic bouquet of contrasting flavors. Re...</td>\n",
       "      <td>Light &amp; Fruity</td>\n",
       "      <td>http://www.wine.com/v6/Schug-Sonoma-Coast-Pino...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author       date       location rating  \\\n",
       "0  colbyalbo  5/20/2016  Lafayette, LA      5   \n",
       "\n",
       "                                              review           style  \\\n",
       "0  An aromatic bouquet of contrasting flavors. Re...  Light & Fruity   \n",
       "\n",
       "                                                 url  url_no  \n",
       "0  http://www.wine.com/v6/Schug-Sonoma-Coast-Pino...       0  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the user reviews and write to a file\n",
    "review_df = aggregate_data(review_list)\n",
    "review_df = pd.concat(review_df, axis=0)\n",
    "review_df.to_pickle('../priv/pkl/00_wine_dot_com_review_combined.pkl')\n",
    "\n",
    "review_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many files are missing\n",
    "find_missing(data_df.url_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5725"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quite a few have no user reviews--not that surprising\n",
    "len(find_missing(review_df.url_no.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 322,  859, 3754, 7595])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_missing(np.array(images_list)) # only four are missing photographs"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
